# ğŸ§  XAI-PGM-Counterfactuals: Explainable AI with Probabilistic Graphical Models

## ğŸ“Œ Overview
This project presents a **novel Explainable AI (XAI) framework** integrating **Convolutional Neural Networks (CNNs)** and **Probabilistic Graphical Models (PGMs)** to provide **counterfactual explanations** for AI-driven medical diagnoses. The methodology focuses on **interpreting CNN predictions** in a **pneumonia classification task** using **chest X-ray images**, enhancing transparency in AI-driven decision-making.

### **ğŸ”¹ Key Contributions**
âœ” **CNN Feature Extraction:** Identifies **critical regions** in medical images.  
âœ” **Prototype-Based Explainability:** Maps CNN **feature maps** to interpretable regions.  
âœ” **Bayesian Networks:** Models relationships **between image regions**.  
âœ” **Counterfactual Reasoning:** Evaluates **alternative explanations** for AI predictions.  
âœ” **Comparison with LIME, SHAP, and Grad-CAM:** Benchmarks performance with existing XAI techniques.

---

## ğŸ“‚ Dataset
- **Dataset Used:** [Chest X-ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray) ğŸ“¸  
- **Task:** **Binary classification** (Normal vs. Pneumonia).
- **Feature Representation:** CNN-extracted features from **segmented lung regions**.

---

## ğŸš€ Methodology
### **1ï¸âƒ£ CNN Feature Extraction**
- A **Convolutional Neural Network (CNN)** is trained on chest X-ray images.
- Extracted **feature maps** from the **last convolutional layer**.
- Divided images into a **3Ã—3 grid** for **localized interpretability**.
- **Cosine similarity** is used to compare regions with **prototypes**.

### **2ï¸âƒ£ Prototype-Based Explainability**
- **K-Means Clustering** applied to extracted features for **regional prototypes**.
- **Principal Component Analysis (PCA)** used for feature reduction.
- Similarity between new images and stored prototypes computed using **cosine similarity**.

### **3ï¸âƒ£ Probabilistic Graphical Model (PGM) Construction**
- **Bayesian Network (BN)** created where **nodes represent image regions**.
- BN structure **learned using Hill Climb Search + K2 Score**.
- Conditional Probability Distributions (CPDs) estimated using **Maximum Likelihood Estimation**.

### **4ï¸âƒ£ Counterfactual Generation & Analysis**
- **Region-wise feature similarities** in the Bayesian Network are **modified**.
- Evaluated how **changes in individual regions** affect CNN predictions.
- **Spearmanâ€™s Rank Correlation (Ï) and Weighted Spearmanâ€™s Rank Correlation (WFMÏ)** used to **validate counterfactual results**.
- Counterfactuals compared with **LIME, SHAP, and Grad-CAM**.

---

## ğŸ“Š Results & Key Findings

### **Counterfactual Explanations for CNN Predictions**
| Changed Region | Change (From â†’ To) | Original Prob | New Prob | Change in Prob |
|---------------|--------------------|--------------|----------|---------------|
| **Region 7**  | Medium â†’ High      | 52.53%       | 84%      | +31.34%       |
| **Region 7**  | Medium â†’ Low       | 52.53%       | 26%      | -26.84%       |
| **Region 4**  | Medium â†’ Low       | 52.53%       | 29%      | -23.16%       |
| **Region 0**  | Low â†’ Medium       | 52.53%       | 68%      | +15.50%       |
| **Region 4**  | Medium â†’ High      | 52.53%       | 66%      | +13.72%       |

### ğŸ”¹ **Key Insights**
âœ” **Region 7 is the most critical region** for CNN decision-making.  
âœ” Changes in specific regions **significantly impact pneumonia probability**.  
âœ” **Bayesian Network effectively models** interdependencies between image regions.  
âœ” **Counterfactuals align with LIME, SHAP, and Grad-CAM**, validating interpretability.  

---

